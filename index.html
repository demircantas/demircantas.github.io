<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0//EN">
<html>
<head>
<title>Demircan Tas</title>
<style type="text/css">
	body
	{
		width:1400px;
		text-align: center;
		font-family: "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif;
		font-weight: 300;
		font-size:16px;
		background-color: #FFF;
	}
	hr
	{
		border: 0;
		height: 1px;
		background-image: linear-gradient(to right, rgba(0, 0, 0, 0), rgba(0, 0, 0, 0.75), rgba(0, 0, 0, 0));
	}

	table
	{
		padding: 5px;
	}

	table.pub_table,td.pub_td1,td.pub_td2
	{
		border-collapse: collapse;
		border-bottom: 0px solid #9B9B9B;
		padding-bottom: 10px;
		padding-top: 10px;
		padding-left: 10px;
		width: 1100px;
	}
	td.pub_td1
	{
		width:100px;
	}
	td.pub_td2
	{
	}
	td.year_heading
	{
		color: #3B3B3B;
		font-weight: 700;
		font-size:20px;
	}
	tr {
		background-color: #FFF;
	}

	div#container
	{
		margin-left: auto;
		margin-right: auto;
		width: 1200px;
		text-align: left;
		position: relative;
		background-color: #FFF;
	}
	div#DocInfo
	{
		color: #9B9B9B;
		height: 128px;
	}
	h4,h3,h2,h1
	{
		color: #3B3B3B;
	}
	h2
	{
		font-size:130%;
	}
	p
	{
		color: #000;
		margin-bottom: 20px;
	}
	p.caption
	{
		color: #9B9B9B;
		text-align: left;
		width: 600px;
		font:11px helvetica,sans-serif;
	}
	p.caption2
	{
		color: #9B9B9B;
		text-align: left;
		width: 800px;
		font:11px helvetica,sans-serif;
	}
	#header_img
	{
		position: absolute;
		top: 0px; right: 0px;
	}
	a:link,a:visited
	{
		color: #1367a7;
		text-decoration: none;
	}
	.section_div {
		background-color: #FFF;
		padding: 10px 10px 10px 10px;
		margin: 10px 10px 10px 10px;
		//border: 1px solid #AAA;
	}
	body {
		background-color: #FFF;
	}
	#personal_info {
		background-color: #FFF;
	}
	p.announcement {
		padding: 10px;
		background-color: #EEE;
	}
	img.teaser_img {
		width: 256px;
		display: block;
    margin-left: auto;
    margin-right: auto;
		margin-top: 5px;
		margin-bottom: 5px;
		border: 0px solid black
	}
	img.teaser_img2 {
		width: 206px;
		display: block;
    margin-left: auto;
    margin-right: auto;
		margin-top: 5px;
		margin-bottom: 5px;
		border: 0px solid black
	}
	img.teaser_img3 {
		width: 186px;
		display: block;
    margin-left: auto;
    margin-right: auto;
		margin-top: 5px;
		margin-bottom: 5px;
		border: 0px solid black
	}
	img.photo_of_me {
		border-radius: 20px;
	}
	div.teaser_img_div {
		width: 286px;
	}
	table.personnel td {
		padding: 16px;
		vertical-align: top
	}

	p.research_agenda_list {
		margin: 5px;
	}
  .expandable-text {
    max-height: 26px;
    overflow: hidden;
    transition: max-height 0.5s;
  }
  .expanded {
    max-height: 1000px;
  }
	
</style>

<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-G3M0TMWRBE"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-G3M0TMWRBE');
</script>

</head>


<body>
	<div id="container">

	<div class='section_div'>
	<table id="personal_info">
	<tr>
	<td><img class="photo_of_me" src="https://i.imgur.com/o7VgHzG.jpg" width=180px style="border: 1px solid black; float:left; margin-right:15px"/></td>
	<td>
	<div id="DocInfo">
		<h1>Demircan Tas</h1>
		t a s d @ m i t . e d u<br>
		<a href="https://scholar.google.com/">Google Scholar</a> / <a href="https://github.com/demircantas">GitHub</a> / <a href="https://twitter.com/demircantas">Twitter</a>
	</div><br>
	</td>
	</tr>
	</table>

<div class='section_div'>
	<h2>About me</h2>
	<p>I am a dual MS student in Architecture and EECS at MIT studying design computation, computer vision, and AI.
		<br><br>
		This website is currently under construction, please check back in 24 hours for a more complete version or follow the links below for my outdated websites.
        <br><br>
        <!-- I worked as a technical artist. -->
		<br>
	</p>
	Quick links: 
	<a href="https://fab.cba.mit.edu/classes/863.21/Architecture/people/demircantas/final.html">HTMAA</a> / 
	<a href="https://sites.google.com/view/demircantas">old website</a> / 
	<a href="https://dl.dropboxusercontent.com/scl/fi/bgm07sw9n7vevn0u64hhm/resume-2024.pdf?rlkey=tb99m7lat4sgenoy8jpy4trna&dl=0">Curriculum Vitae</a>
	<br>
	<br>
</div>
<hr>


<div class='section_div' id='ResearchGroup'>
<h2>Research Interests</h2>

I am a dual SM candidate from the Design & Computation Group and EECS at MIT. The Design & Computation group theorizes on computing creative and imaginative processes in artistic, spatial, and industrial practices of design. Working on my thesis, I combine the theoretical discussions of the Design & Computation group with experiments into latent spaces of generative multimodal AI to improve parametric and algorithmic design paradigms. Working as a research assistant for the Urban Metabolism Group led by Prof. John Fernandez in the Environment Solutions Initiative, I combine virtual reality based HCI (human computer interaction), with AI models trained with data from 10,000 cities. During RA work over summer at LCAU, I used auto-encoders and GANs to tackle crowd collaboration for informal neighborhoods in South Africa. I co-founded Construct(), a speech/gesture to blocks AI for Minecraft. Prior to my work at MIT, I built an image to HBIM (heritage building information modeling) pipeline for architectural heritage in Anatolia.

<br><br>
Please click the following to expand details:<br>

<div class="expandable-text" onclick="this.classList.toggle('expanded')">
	<p class="research_agenda_list">&#9656; <i>Design & Computation</i>: Questions into perception and shared embeddings</p>
	<p>	In the study of design computation for architecture and industrial applications, parametric and algorithmic design occupy a central role. However, these approaches map design parameters to narrow solution spaces that often exclude the changes presented by iterations on drawings or physical prototypes. My ongoing thesis work combines image and text conditioned diffusion encoders to sample control vertices for weighted Bezier splines (NURBS) in million-dimensional latent vector spaces. Sampling from trajectories in the latent space using an INR (implicit neural representation) decoder, we find useful non-linear interpolations among 3d objects to mimic manipulation of pseudo parametric transformations. This work has potential use cases in architecture and construction, as well as industrial and medical applications' design. For this work, I created a custom NURBS implementation, optimized for splines in 1,000,000 dimensional vector spaces.<br>
		<a href="https://github.com/demircantas/inverse-drawings">Inverse Drawings</a>, 
		<a href="https://github.com/demircantas/pixel-rules">Pixel Rules</a></p>
</div>

<div class="expandable-text" onclick="this.classList.toggle('expanded')">
	<p class="research_agenda_list">&#9656; <i>Virtual Reality and HCI</i>: Work examples from my research at <a href="https://environmentalsolutions.mit.edu/">ESI</a></p>
	<p>The Gorge VR project for <a href="http://climatemachine.mit.edu/">MIT Climate Machine</a><br>
		<iframe width="560" height="315" src="https://www.youtube.com/embed/4M-ik_BxZXU?si=rGKkvPX3Vzb7cfSM" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe><br>
		<br>
	</p>
	<p>
		Wolman Game for MIT Urban Metabolism Group<br>
		<iframe width="560" height="315" src="https://www.youtube.com/embed/0q4i7rGeTOk?si=xHeNEwJ4Aa_BnqKI" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe><br>
	</p>
</div>

<div class="expandable-text" onclick="this.classList.toggle('expanded')">
	<p class="research_agenda_list">&#9656; <i><a href="https://www.construct.place/">Construct()</a></i>: Speech to Minecraft blocks</p>

	<p>
		Design X pitch for Construct()<br>
		<iframe width="560" height="315" src="https://www.youtube.com/embed/yIcagfR6jF0?si=t4KC014IhgheIoQQ" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe><br>
	</p>

	<p>Hands on (or off) demo of Construct()<br>
		<iframe width="560" height="315" src="https://www.youtube.com/embed/TXLQM7l2Dtg?si=IH0cxyVWMTM5LFo_" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe><br>
		<br>
	</p>
</div>

<br>
I collaborate with peers from diverse background to develop imaginative AI.
<br>
while developing natural and precise interfaces.
<br><br>
<table class='personnel'>
	<tr>

		<td>
			<!-- <b>EECS studies</b><br> -->
				<div class="expandable-text" onclick="this.classList.toggle('expanded')">
					<p class="research_agenda_list">&#9656; <i>Demoreel (click to expand)</i></p>
					<p>A brief demoreel of projects I worked on during my studies at MIT<br>
						<iframe width="560" height="315" src="https://www.youtube.com/embed/T-7O1tRrVug?si=GSnNP7aLKpxBeOdT" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
				</div>
		</td>

		<td rowspan="2" width=400px>
			<!-- <b>Studies (click to expand)</b><br> -->

				<div class="expandable-text" onclick="this.classList.toggle('expanded')">
					<p class="research_agenda_list">&#9656; <i>Prototypes (click to expand)</i></p>
					<p>Pixelation board: Non electronic board composed of varying light diffusers for optical computing</p><br>
						<iframe width="560" height="315" src="https://www.youtube.com/embed/G6X04jujA8A?si=e_Kgdg4Jn0Xro0PP" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
					<p><br>
				</div>

		</td>

	</tr>
	<tr>
	</tr>
	<tr>
		<!-- <td colspan=2>
			<b>Showreels (click to expand)</b><br>

				<div class="expandable-text" onclick="this.classList.toggle('expanded')">
					<p class="research_agenda_list">&#9656; <i>Demoreel</i></p>
					<p>A brief demoreel of projects I worked on during my studies at MIT<br>
						<iframe width="560" height="315" src="https://www.youtube.com/embed/T-7O1tRrVug?si=GSnNP7aLKpxBeOdT" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
				</div>
		</td> -->
	</tr>
</table>

</div>
<br>
<hr>


	<div class='section_div' id='Papers'>

	<h2>Recent Work (<a href="/papers.html">All papers</a>)</h2>

	<table class="pub_table">

		<tr>
			<td class="pub_td1">
				<div class="teaser_img_div">
					<a href="https://docs.google.com/presentation/d/1FzgJtsVNAuLumm6Qjo6OxG1IIChP6xJpWerh7YMsF8w/edit?usp=sharing">
						<img class="teaser_img" src="https://i.imgur.com/19Yhada.png" width=256px>
					</a>
				</div>
			</td>

			<td class="pub_td2">
				<b>
					Parametric Paint-Over (previously Sketch-Vision)
				</b>

				<br> Demircan Tas <br>
				<i> Ongoing joint thesis work for SMArchS (Design & Computation) and SM EECS degrees</i>.<br>
				[<a href="http://arxiv.org/abs/2312.12270">Interim Report</a>]
				[<a href="https://docs.google.com/presentation/d/1FzgJtsVNAuLumm6Qjo6OxG1IIChP6xJpWerh7YMsF8w/edit?usp=sharing">Presentation</a>]
			</td>
		</tr>

		<tr>
			<td class="pub_td1">
				<div class="teaser_img_div">
					<a href="https://youtu.be/WRnXjt55kaw">
						<video width="100%"width="100%" height="100%" muted autoplay loop style="border-radius:7.5px;border:0px solid #e1e1e1">
							<source src="https://i.imgur.com/8P3HkFw.mp4" type="video/mp4">
						</video>
					</a>
				</div>
			</td>

			<td class="pub_td2">
				<b>
					TeamCAD - A Multimodal Interface for Remote Computer Aided Design
				</b>
				<br> Demircan Tas, Dimitrios Chatzinikolis <br>
				<i> Report for 6.835, Intelligent Multimodal User Interfaces at MIT, Spring 2022</i>.<br>
				<i> CHI 2024 submission(under review)</i>.<br>
				[<a href="http://arxiv.org/abs/2312.12309">Paper</a>]
				[<a href="https://youtu.be/WRnXjt55kaw">Video</a>]
				
			</td>

		</tr>
		
		<tr>
			<td class="pub_td1">
				<div class="teaser_img_div">
					<a href="https://youtu.be/WRnXjt55kaw">
						<img class="teaser_img" src="https://i.imgur.com/f4fAsoE.png" width=256px>
					</a>
				</div>
			</td>

			<td class="pub_td2">
				<b>
					UNVEILING SPACES: Architecturally meaningful semantic descriptions from images of interior spaces
				</b>
				<br> Demircan Tas, Rohit Priyadarshi Sanatani <br>
				<i> Project report for 6.869, Advances in Computer Vision at MIT, Spring 2022</i>.<br>
				[<a href="https://dl.dropboxusercontent.com/scl/fi/tztev60ilp3metu4sillj/unveiling-spaces.pdf?rlkey=w20aeu8y4nf89x4a8n9zo30x8&dl=0">Paper</a>]
				
			</td>

		</tr>

		<tr>
			<td class="pub_td1">
				<div class="teaser_img_div">
					<a href="https://i.imgur.com/7AUqIlI.png">
						<img class="teaser_img" src="https://i.imgur.com/7AUqIlI.png" width=256px>
					</a>
				</div>
			</td>

			<td class="pub_td2">
				<b>
					Geo-located Aspect Based Sentiment Analysis (ABSA) for Crowdsourced Evaluation of Urban Environments
				</b>

				<br> Demircan Tas, Rohit Priyadarshi Sanatani <br>
				<i> Final project for 6.8610, Quantitative Methods for Natural Language Processing at MIT, Fall 2022</i>.<br>
				[<a href="http://arxiv.org/abs/2312.12253">Paper</a>]
			</td>
		</tr>
		
	

	</table>

	</div>


<h2>Subjects TA'd</h2>
<a href="https://fab.cba.mit.edu/classes/863.22/Architecture/index.html">6.902(0): How to Make (almost) Anything</a> (Fall 2022)<br>
<a href="http://6.869.csail.mit.edu/sp23">6.8300/6.8301: Advances in Computer Vision</a> (Spring 2023)<br>
6.8300/6.8301: Advances in Computer Vision (Spring 2024)<br>
</div>

<div class='section_div' id='Courses'>
<h2>Subjects Taken</h2>
<a href="https://fab.cba.mit.edu/classes/863.21/Architecture/index.html">6.943: How to Make (almost) Anything</a> (Fall 2021)<br>
6.835: Intelligent Multimodal User Interfaces (Fall 2021)<br>
<a href="http://6.869.csail.mit.edu/sp22">6.819/6.869: Advances in Computer Vision</a> (Spring 2022)<br>
6.8610: Quantitative Methods for Natural Language Processing (Fall 2022)<br>
<a href="https://www.scenerepresentations.org/courses/inverse-graphics-22/">6.S980 Machine Learning for Inverse Graphics</a> Fall 2022<br>
<a href="https://designx.mit.edu/"> 11.246: DesignX Accelerator</a> (Spring 2023)<br>


<hr>

</body>

</html>
